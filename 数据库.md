[TOC]



# 数据库

### 三大范式

为了设计**冗余较小、结构合理**的数据库而制定的一些规则。

第一范式 1NF： 每一列具有**原子性**，不可分割

>学生有姓名 可以分割成 firstName LastName 姓 和 名  这就需要考虑你业务逻辑需要涉及的最低粒度

第二范式 2NF：在1NF的基础上，表中的每列必须全部依赖于主键。

>学生选课 学号 课程号 学生名称 课程名称 显然学生号和 课程号是主键的话 你学生名称 只部分依赖于学号 课程名称也部分依赖于课程号

第三范式 3NF : 在2NF上消除传递依赖

> 学号 学生姓名 班主任工号 班主任姓名  学号是主键 其他三列都依赖于这个主键，但是显然班主任姓名直接依赖是班主任工号

范式化：减少数据冗余 更新快 表小 但 表关联多 增加了索引优化的难度。

反范式化 ：减少表的关联，更好进行索引优化，存在数据容易，修改成本更高。

## 索引

### 存储、索引结构

InnoDB 存储引擎的最小存储单元是页 默认 16K 

xfs最小单元是块 默认4K   磁盘最小单元是扇区 默认512字节

每一页 可以用于存放数据 也可以用于存放键值+指针

在 B+ 树中叶子节点存放数据，非叶子节点存放键值+指针。

### 什么是索引

索引相当于提供一个目录也可以理解为排好序，大大提高查询效率，常用的有Hash索引和B+树索引结构

> 比如查字典 从先找ABCD

### 为什么使用B+树而不使用B树 平衡二叉树 ？

InooDB 以页为基本的存储单位的，默认16K，无论是B树还是B+树，每个节点都是由一页来存储，但在B树上 非叶子节点会存数据记录，而相比之下B+树非叶子节点 不存任何数据，只保存key和指针，这样能够放下更多的索引结点，这样的树更宽更矮，IO次数由树的高度决定，磁盘IO少。

并且B+树叶子节点构成了一个有序链表，在区间内查询数据时效率更高，做全表扫描也更快。

### 聚集索引

物理结构

Innodb是聚集索引，物理结构，一个表有且只能由一个聚集索引，默认是给主键建立的索引，如果主键没有就第一个非空唯一索引，或者自动生成隐式Rowid，行数据和主键B树是存在一起的，也就是B树的叶子节点就是一个页，这个页里面都是数据记录，还是有序的，方便二分查找。

对于Innodb 其他索引是辅助索引，因为一个表只能有一个索引，B树叶子节点存放的是key喝对应的主键，需要再搜一遍聚集索引。因此不建议使用过长的主键，会使得辅助索引变得过大建议使用自增字段作为主键。

MyISM是非聚集索引，表结构存储在独立的地方，叶子节点等使用指针指向真正的表数据

>相关数据存储在一起，方便遍历 邮件
>
>主键索引访问更快，索引和数据保存在一起，而非聚集索引叶子节点最终存储的也是指向数据记录的指针，这样就少一次IO
>
>- **使用覆盖索引扫描的查询可以直接使用页节点中的主键值。**
>
>辅助索引使用主键作为指针，而不使用地址作为指针，减少了行移动或者数据分页时对辅助索引的维护工作。
>
>
>
>坏处：
>
>插入速度依赖插入顺序
>
>更新代价高
>
>插入可能导致页分裂 （在某一页中间插入）
>
>页分裂导致全表扫描变慢
>
>二级索引增大
>
>二级索引访问需要两次索引查找，而不是一次
>
>重大问题：二级索引主键顺序和一级索引不一致，出现大量跳读现象，

### 什么是回表？

Innodb是聚集索引 也就是有且只有一个主键索引，有辅助索引，主键索引的叶子节点存放的是数据记录，而辅助键索引的叶子节点存放的是主键-辅助键，因此通过辅助键得到主键后，还需要再查一次主键索引，才能得到那一行数据记录。

### 页内查找

Innodb页内利用槽实现分组二分查找

### 普通索引和唯一索引

查找：普通索引查找到对应的K和后继续进行查找。 唯一索引查到对应的Key即停止

更新：普通索引可以利用change buffer 将更新记录先写入缓存中，当触发merge的时候再将更新写入磁盘。唯一索引每次插入都要检查key是否唯一来判断合法性，因此要搜一遍更新后的key看是否唯一,这时候就已经搜到对应的数据页了，也没有必要写缓存了。

>那如果只是改变非key的属性呢？ 索引是根据这个key构建的，（因为总要给一个主键 有一样的话 更新后面的值，没有一样的话是插入）
>
>写多读少的应用适合使用普通索引 比如日志系统
>

###  覆盖索引

索引的叶子节点包含了要查询的数据，不需要再回表查询了。

### 联合（复合）索引/最左匹配

最左匹配 当你查询的语句where条件 用到了某个联合索引最左边的那些索引 就可以使用联合索引来查询

将区分度高的字段放在前面，将区分度低的字段放在后面

and前后顺序无所谓 优化器自动优化

 但是当遇到范围查询时 (>,<,between,like) 就会停止匹配（多Key值的B+树 第2列后面的列 全局无序、局部有序）

### 什么时候建索引

索引不是越多越好 大量索引占空间 影响 插入删除性能（虽然说聚集索引没那么影响）

避免对经常更新的表建索引

数据量少的表没必要建索引

在不同值较多的列上建索引，对于联合索引，在区分度尽可能大的列上建索引

在频繁排序或分组的列上建索引

### 索引类别

* 物理存储
  * 聚集索引和非聚集索引
* 数据结构角度
  * B+树，B树，哈希索引，fulltext索引,R-tree 索引
* 逻辑角度
  * 主键索引 特殊的唯一索引 不允许有空值
  * 唯一索引、普通索引
  * 单列索引、符合索引
  * 空间索引 对空间数据类型建立的索引 （GEOMETRY、POINT、LINESTRING、POLYGON）

### 哈希索引

key-->buckets-->entries

范围检索 纯垃圾

不支持多列索引

大量重复键值时 纯垃圾



### 索引失效的场景有哪些？

这个世界上的查找，说白了只有基于有序的二分查找，当你的查询结果是无序的时候，肯定就无法索引，不得不扫表。

其次就是优化器也想明白没法给你优化成有序的了 或者是 优化器觉得你扫全表更快

1. 不满足最左前缀匹配
2. 满足最左但在中间使用了范围条件
3. 在索引上加了 函数操作  ！!= not in
4. 索引字段使用or (如果两个字段都有索引 那会走两个索引)
5. 使用like 模糊匹配 然后%在最前面（前导模糊查询）
6. 索引列 is null不一定失效 ><也不一定失效

### 索引下推

在非主键索引上进行优化，有效减少回表次数

因为Innodb要在辅助索引上先查，如果辅助索引上对应的KEY是包含在判断条件里的，就可以先判断是否满足条件，再发给MYSQL服务器来进行二级索引，减少回表次数。

### 一些规定

一次查询MYSQL只能使用一个索引 因此多个单列索引 没弔用





## 事务

### 什么是事务？

事务本身是一系列数据库操作，但这些操作必须全部完成，有一个失败都不行，有一个失败就得全部失败。

```sql
START TRANSACTION;
SELECT balance FROM CMBC WHERE username='lemon';
UPDATE CMBC SET balance = balance - 1000000.00 WHERE username = 'lemon';
UPDATE ICBC SET balance = balance + 1000000.00 WHERE username = 'lemon';
COMMIT;
```

### 事务的四大特性ACID

* 原子性 (atomicity） [ˌætəˈmɪsəti]：事务被视为不可分割的最小工作单元，要么全执行，要么全拉倒
* 一致性（consistency)：[kənˈsɪstənsi] 事务总是使得系统从一个一致性状态转移到另一个一致性状态,事务提交，完成整个修改，事务回滚，回到原来状态，事务保证不会读到中间状态的数据。 举例 银行 A卡-100 B卡不+100的情况 AID是手段 C是目的 
* 隔离性（isolation）[ˌaɪsəˈleɪʃn] 多个并发的事务相互隔离，一个事务在最终提交之前对其他事务是不可见的。在执行第三条语句之前，A银行里还是有100个W的
* 持久性(durability)  [ˌdjʊərəˈbɪlɪti]  一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。

### 什么是脏读、不可重复读、幻读

* 脏读 读到了其他事务未提交的数据，这些数据可能被更新、回滚，不一定最终还会存在在数据库中，叫脏读。
* 不可重复读 同一个事务内，不同时刻读到的数据可能是不一样的。
* 幻读 按照条件读取某个记录时，事务B插入了新的满足条件的记录，事务A再次按照该条件查询时，会产生新的满足条件的记录（幻行）

不可重复读的重点是修改：同一事务，同样条件，两次读到的数据不一样，因为中间有其他事务提交了修改。

幻读的重点是插入或删除：同一事务，同一范围查询条件，两次读到的行数不一样，或者说该不一样的，结果一样了，因为中间有其他事务进行了插入或删除。

### SQL的四个隔离级别

| 隔离级别                                     | 特性                                                         | 白话                                       | 脏读 | 不可重复度 | 幻读 |      |
| -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------ | ---- | ---------- | ---- | ---- |
| Read Uncommitted 未提交读                    | 所有事务都可以看到其他事务未提交的修改，导致诸多问题         | 能够读取到其他事务还未commit的数据         | √    | √          | √    |      |
| Read Committed 提交读                        | 一个事务只能看到其他已经提交的事务所作的变更                 | 只能读取到已经Commit的数据                 | ×    | √          | √    |      |
| Repeatable Read 可重复读                     | 确保同一事务的多个实例在并行读取数据时会看到相同的数据行 MYSQL默认 | 一个事务内任意时刻读到的同一批数据是一致的 | ×    | ×          | √    |      |
| Serializable  [ˈsɪərɪəlaɪzəbl]<br />可串行化 | 事务串行执行，读取每一行都会加锁，导致大量的超锁和锁争用问题 实际情况中除非非得保证数据一致性  否则不考虑该级别 | 串行执行                                   | √    | √          | √    |      |

### 如何保证事务的隔离性？加锁

锁可太多了 往下看

#### 悲观锁 乐观锁

悲观锁：以悲观态度加锁，在修改数据之前独占锁，然后再对数据进行读写，在此期间，其他任何人都不能对数据进行操作，直到操作完成后释放锁。

完全保证数据的独占性 但是请求锁、释放锁性能消耗太高。

乐观锁：对数据冲突保持乐观态度，操作时不会对数据加锁，直到数据提交时才通过某种机制来验证是否存在冲突，一般是通过版本号来实现

介绍了加解锁操作，提高了性能  但高并发场景存在大量请求冲突 性能并不乐观？？

#### 加锁的目的

解决事务隔离性问题，让事务之间的操作互不影响

#### 锁的实现

锁是基于索引实现的

#### 锁的种类

* 基于锁的属性
  * 共享锁（share Lock）S锁 当一个事务加上读锁之后，其他事务只能对该数据加读锁，不能加写锁，直到所有读锁释放后才能加写锁。避免了不可重复读
  * 排他锁（eXclusive Lock）X锁  当一个事务为数据加锁后，其他请求不能为其加任何锁，直到该锁释放。避免脏读
* 基于锁的粒度
  * 表锁：锁整张表
  * 行锁：锁一行
  * 间隙锁：锁记录和记录之间的gap
  * 临建锁: next-key lock =gap+record锁
* 特殊
  * 自增锁：插入前申请 +1  插入成功后释放 表级锁
  * 意向锁：实现多粒度锁机制，为了让表锁行锁都能用

### MVCC （Multi-Version Concurrency Control)

核心：读不加锁，读写不冲突，增加并发场景下的吞吐性能。

>通过readview 和版本链实现，版本链保存历史记录，readview判断当前事务的可见性，如果不可见，从版本链中找上一个可见版本
>
>版本链通过表的三个隐藏字段实现，DB_TRX_ID,事务id DB_ROLL_PRT,回滚指针 DB_ROLL_ID主键
>
>readview可以理解成某个时刻的状态拍成的照片，在获取某个时刻的数据时，在该时间点拍的照片上找数据？（还是没明白）

数据有多个版本，通过版本号实现非阻塞模式的读，记录在Undolog中，并且每个记录都有指向undolog的指针以及版本号作为隐藏列

读操作可以分为两类：

* 快照读（snapshot read) 读取记录的可见版本 不用加锁

  ```sql
  select * from table where ?; # 不加锁 快照读
  
  # 当前读
  select * from table where ? lock in share mode; #加S锁
  
  # 加X锁 因为插入更新删除语句都会先进行 current read 然后return & lock 然后update  然后success 然后继续 current read直到更新结束
  select * from table where ? for update 
  insert * table values (..)
  update table set ? where ?
  delete from table where ?
  ```

  

* 当前读（current read) 读取记录的最新版本 会加锁 

对应隔离级别：

* Read Uncommitted ： 可以看到未提交的记录
* Read Committed： 针对当前读 可能出现，RC隔离级别保证对读的记录加记录锁，可能导致幻读现象
* Repeatable Read ： 针对当前读，对读取到的记录加记录锁，同时对读取的范围加gap nextkey
* serializable： MVCC并发控制退化为基于锁的并发控制，所有读都是当前读，读加读锁，写加写锁，并发度急剧下降

锁是加在索引上的！！！！！！ 没索引时全表都加！！！普通查询用快照读 不加锁的！！！走索引的查询在对应索引上加锁！！如果没有索引，也会在聚集索引s上加锁!!如果有外键约束 也要给外表索引加锁！！很合理！！

上啥锁 取决于

* Innodb隔离级别
* 能不能读快照？
* 走不走索引？
* 走主键索引还是二级索引？
* 走二级索引唯一还是非唯一？

innodb  RR模式下 快照读 会存在幻读 但是当前读 **select for update/lock in share mode** 可以避免幻读

#### 实现原理

innodb对每一行都加了两个隐含的列 更新时间和删除时间 （用递增的版本号（事务号）代表时间）

select: 更新时间 ≤ 当前时间    and    删除时间＞ 当前时间

insert 新插入的行更新时间=当前时间

#### 为什么select count * 在myisam表上快 innodb表上慢？

MVCC存在多个版本需要进行过滤。

#### 表只是更新 没有插入 表空间却越来越大

记录的版本太多了 也没更新

### 为什么不要使用长事务

1. 并发太多，连接池撑爆
2. 占用锁资源
3. 主从延迟（写Binlog）
4. 回滚所需要的时间长
5. undolog日志越来越大 存着很多很老的视图，这个事务随时可能回滚，所以特么还得把记录存着。 

## 引擎

### Myisam和Innodb的区别

* innodb支持事务，myisam不支持
* innodb支持行表锁，myisam只有表锁
* innodb是聚集索引，myisam是非聚集索引
* innodb有redolog日志文件，myisam没有
* innodb支持MVCC，对并发性事务性能更好
* innodb支持外键 myisam不支持

### 查询语句执行过程

select * from Table where id=1;

连接器：建立TCP连接，获取用户权限，接受用户输入的语句

有长连接短连接之分，尽量建立长连接，但是容易占内存。

查询缓存（Query Cache） 看之前是否执行过相同语句 Mysql8.0后就删了 

分析器：词法分析、语法分析

优化器：优化处理，使用哪一个索引、表的连接顺序，不一定是最优的

执行器：权限验证、调用存储引擎

### 更新语句是如何执行的

连接器-权限校验-分析器-优化器-选择计划-执行器-校验权限-buffer pool 未命中--读磁盘--写undolog---更新---写redolog--事务Commit---redolog+ Prepare---server写undolog---redolog+commit  -- 事务提交--触发落盘条件后写磁盘 当然还有windows还有一层文件缓冲



### Buffer Pool

数据结构：

* LRU链表：old list 和 new list  读一个页时先丢到oldlist里 ，用户读取记录时才放到new里，避免预读把真正的热数据挤到下面
* Free链表：空闲的缓存页，双向链表 为什么要双向链表 主要是为了插入删除中间链表方便
* Flush链表：管理Buffer中的脏页，线程定时刷脏（脏页是指对缓存也进行了修改，但还没写回，缓存数据和磁盘数据不一致）

### change buffer 

Buffer Pool中的一块内存 用来存储变更记录

写完redolog后 等待实际更新磁盘中的数据文件（刷脏），用来缓冲写操作的内存就是change buffer

undo log buffer存的是过去的日志，change buffer存的是 要往磁盘上覆盖的

普通索引修改时会组change buffer。



## 各种LOG

### Undo log （事务回滚,MVCC）

记录数据修改前的日志，在表信息被修改之前先将数据拷贝入undo log中,事务回滚时进行还原

在MVCC多版本控制中，通过读取undo log历史版本可以实现一条记录有多个快照版本。

### Redo log

只有Innodb才有

修改数据时，先写redolog，还包括buffer，等需要清脏页的时候再进行写到数据库

redo log写磁盘时机：每次事务提交 或者  1S一次

用于数据库故障恢复（掉电，宕机）

redolog 有四个日志文件循环写 头指针尾指针 做清空和继续写

### bin log

记录了表结构和数据的变更

用于复制或恢复数据（主从）

binlog记录了数据的逻辑变化 redolog记录数据的物理变化	

binlog事务提交后才有 redolog 事务开始时才有

写binlog和写redolog都成功了 事物才算成功

### 两阶段提交

1. 将更新写redolog  并设置redolog 为prepared状态
2. 将更新写入binlog 事务提交 redolog改成commit状态

> 为什么要两阶段提交：
>
>  保证redolog和binlog数据一致 保证数据库恢复、主从复制的一致性
>
> 如何保证：
>
> 1->prepare->2->commit->3
>
> 1出问题 redolog还没写 等于事务回退
>
> 2出问题 通过redolog判断是否完整， 如果Binlog完整提交事务，不完整 回滚事务
>
> 3出问题 直接用redolog恢复
>
> 数据恢复过程：
>
> 顺序扫描redolog 如果redolog既prepare 又commit 直接提交
>
> 如果只有prepare 没有commit拿着redolog的XID找Binlog 看binlog是否完整。

### redo LOG和 bin LOG的区别

都属于持久化保证，但侧重点不同：

redolog 让Innodb引擎有了崩溃回复的能力

binlog 让保证了MYSQL集群的一致性 

Undo log来回滚日志 保证事务的原子性

* redolog 是innodb独有的 而 binlog 是server层的 
* redolog记录操作的页以及对应的具体数值 binlog是操作逻辑语句 物理/逻辑
* redolog可以4个日志文件形成一组 循环使用 binlog达到上限继续刷
* redolog 能够崩溃回复 binlog归档 一致性

### WAL的好处

write ahead logging 所有修改先写入日志再写入磁盘

随机写 变成了顺序写

读写并发执行 不会相互阻塞

可以使用日志进行数据库恢复	

## 主从

为啥要用主从？

- 提高数据库负载能力，主库执行读写任务（增删改），备库仅做查询。
- 提高系统读写性能、可扩展性和高可用性。
- 数据备份和容灾

### 主从复制：

将主库的DDL和DML操作通过二进制日志传递到从库上，然后对这些日志重新执行，使得主从数据库一致。	、

1. 主库有数据更新时，写入binlog，创建log dump线程通知slave有数据更新
2. 从库IO线程向binlog线程请求一份指定位置的log文件，存到本地relaylog中，还要写入binlog中，以便知道下次请求哪里
3. sql线程读relaylog中的日志，并将其解析成SQL语句逐一执行，sql线程实时检测relaylog文件中是否有新增内容



* 全同步复制：所有从库都执行完毕才返回客户端

* 半同步复制：主库收到一个从库确认就认为操作成功，从库写入成功后返回ack确认



### 并行复制

MYSQL本身是并发执行SQL的，但是从库sql线程只有一个，只能串行读sql，会造成主从延迟，为了提高relaylog的写速度，将sql线程演化成了一个coordinator 和多个work的线程，按照生产者消费者模式 进行，可以实现并行【回放】，

### 为什么会产生主从同步延迟

1. 从库机器性能差
2. 从库压力大，从库承担读任务，大量查询在从库上
3. 大事务执行，产生贼大的binlog，十几个G传输非常慢
4. 锁冲突
5. 从库的复制能力，主库一直写，从库跑得慢，就是跟不上。。。

### 主从延迟怎么解决

1. MYSQL 并行复制能力
2. 提高机器配置
3. 分库分表，避免单表过大
4. 避免长事务
5. 避免让数据库进行大量运算
6. 对延迟很敏感的业务使用主库读，降低从库压力

## 分布式事务

### 2pc两阶段提交

引入事务协调者的角色来协调管理各参与者的提交和回滚，两阶段分别是：

1）准备阶段：事务协调者向各个事务参与者发起询问请求：“我要执行全局事务了，这个事务涉及到的资源分布在你们这些数据源中，分别是……，你们准备好各自的资源（即各自执行本地事务到待提交阶段）”。各个参与者协调者回复 yes（表示已准备好，允许提交全局事务）或 no（表示本参与者无法拿到全局事务所需的本地资源，因为它被其他本地事务锁住了）或超时。

2）提交阶段：如果各个参与者回复的都是 yes，则协调者向所有参与者发起事务提交操作，然后所有参与者收到后各自执行本地事务提交操作并向协调者发送 ACK；如果任何一个参与者回复 no 或者超时，则协调者向所有参与者发起事务回滚操作，然后所有参与者收到后各自执行本地事务回滚操作并向协调者发送 ACK。

* 强一致性设计
* 同步阻塞协议：第一阶段些调整等待所有参与者响应才会进行下一步操作，第二阶段出问题了只能头铁重试哈哈哈哈

2PC协调者故障问题：

* 协调者宕机，参与者收不到提交、回滚命令，不知所措
* 参与者未返回ACK，网络二将军问题

因此 2PC是一种尽量保证强一致性的分布式事务，因为他是同步阻塞的，效率低，而且存在单点故障问题，极端条件下也会出现数据不一致的风险。

### 3PC阶段

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/uChmeeX1Fpx2WyATKXiadnNrvpBPNyme86EFEmv5s5sricicFs5t4J3XT8AVTWvhzic9wMYCkzwGVNBX2zJiaoGLt7w/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)



1. CanCommit:准备阶段，询问参与者是否有条件接受事务，你还好吗？忙不忙？ 
2. PreCommit：之前兄弟们发准备好了立马开始干活，现在是预提交之后就开始干活，这时候统一好状态，不会有兄弟抢先干，结果等别的兄弟一直等不到
3. DoCommit：提交阶段

3PC解决了2PC同步阻塞问题，避免资源被永久锁定，加强了事务的可靠性，出现数据不一致性的可能性更小，但是性能有所下降且还会出现问题。

2PC 3PC场景有限，必须使用实现了XA协议的数据库作为参与者才能完成，但比如说利用API接口相互调用服务时就不遵守XA协议了。

### TCC

Try \ Confirm \ Cancel

1）阶段一：准备阶段。协调者调用所有的每个微服务提供的 try 接口，将整个全局事务涉及到的资源锁定住，若锁定成功 try 接口向协调者返回 yes。

2）阶段二：提交阶段。若所有的服务的 try 接口在阶段一都返回 yes，则进入提交阶段，协调者调用所有服务的 confirm 接口，各个服务进行事务提交。如果有任何一个服务的 try 接口在阶段一返回 no 或者超时，则协调者调用所有服务的 cancel 接口。

网络二将军问题如何解决，每个参与者维护去重表，记录全局事务，若已经进行过，不再重复进行。

由支付宝团队提出的，比如买基金会先冻结一部分余额，这等于准备阶段锁住。

### 本地消息表

| 分布式事务 ID   | 事务内容                                                     | 事务状态                                                |
| :-------------- | :----------------------------------------------------------- | :------------------------------------------------------ |
| global_trx_id_1 | 操作 1：调用 repo-service 扣减库存 操作 2：调用 order-service 生成订单 | 状态 1：初始 状态 2：操作 1 成功 状态 3：操作 1、2 成功 |

协调者维护一个事务状态表，每成功调用一次更新一次状态，如果状态一直没有到3，重新调用操作1 2，每个服务的接口基于事务ID做全局幂等

### 消息事务

要看消息队列支不支持消息事务

场景：order-service 生成订单 repo-service 扣减库存 

order-service  中 在 t_order 表添加订单记录 && 在 t_local_msg 添加对应的扣减库存消息

检查本次扣库存操作是否已经执行过 &&  执行扣减库存如果本次扣减操作没有执行过 && 写判重表 && 向 MQ sever 反馈消息消费完成 ACK

如果支持消息事务：

第一步先给 Broker 发送事务消息即半消息，**半消息不是说一半消息，而是这个消息对消费者来说不可见**，然后**发送成功后发送方再执行本地事务**。

再根据**本地事务的结果向 Broker 发送 Commit 或者 RollBack 命令**。

并且 RocketMQ 的发送方会提供一个**反查事务状态接口**，如果一段时间内半消息没有收到任何操作请求，那么 Broker 会通过反查接口得知发送方事务是否执行成功，然后执行 Commit 或者 RollBack 命令。

如果是 Commit 那么订阅方就能收到这条消息，然后再做对应的操作，做完了之后再消费这条消息即可。

如果是 RollBack 那么订阅方收不到这条消息，等于事务就没执行过。

### 最大努力通知

都算最大努力通知

2PC 3PC TTC 提交阶段失败都会接着硬怼

本地消息表后台查看未完成的消息，一直未完成就硬怼直到超时

如果消费不了会重试

**最大努力通知其实只是表明了一种柔性事务的思想**：我已经尽力我最大的努力想达成事务的最终一致了。  

### seata事务框架

不会用嘿嘿

## FAQ

### 为什么选用自增id作为主键？

* 普通索引会有id，如果id列过大，占用空间过大
* 聚集索引会导致表分裂
* 聚集索引顺序插入更高效

### 一条SQL语句一直查询慢的原因

* 没有用到索引
* 表数据量太大
* 优化器选错了索引

### 一条SQL语句查询偶尔慢的原因

* CPU干别的去了 （刷脏页，啥时候需要刷呢，redolog满了，内存不够用了，定时到了）
* 没拿到锁

### 为什么不建议VARCHAR大于255？

* 大于255占两个字节占用空间大

* 索引失效

### SQL调优思路

* 表结构优化
  * 拆分字段
  * 字段类型选择
  * 字段长度限制
  * 合理增加冗余字段
* 索引
  * 建立合适索引
  * 利用索引下推、覆盖索引的性质
  * 唯一索引、普通索引的选择
* 优化查询
  * 避免索引失效
  * 优化查询条件的顺序
  * 小表带动大表
  * 强迫索引
* 分库分表

### 为啥不建议使用外键？

阿里强制规定一切外键和级联概念都应该在应用层解决

外键适合单机低并发，保证了数据库一致性、完整性，级联操作方便。

但不适合分布式、高并发集群，级联更新是强阻塞，存在数据库更新风暴的风险，影响插入速度。

### 批量SQL查询

* select * from table limit m,n 从第m个偏移开始 找n个 会先遍历前m项，插入速度慢
* 直接where id>m  对起始位置进行重新定义
* 禁止100页以后的数据
* select少查点列

### 批量插入

写在一个句子里，不然会插入语句默认会开启事务和进行事务提交，会进行表锁

